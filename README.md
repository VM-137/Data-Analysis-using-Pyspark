## Data-Analysis-using-Pyspark
* Prepare the Google Colab for distributed data processing
* Mounting our Google Drive into Google Colab environment
* Importing first file of our Dataset (1 Gb) into pySpark dataframe
* Applying some Queries to extract useful information out of our data
* Importing second file of our Dataset (3 Mb) into pySpark dataframe
* Joining two dataframes and prepapre it for more advanced queries
* Learn visualizing our query results using matplotlib
